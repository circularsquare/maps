{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "821d0430-2295-45cd-b176-9d49bbfd4be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm, NoNorm, PowerNorm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy.spatial import KDTree\n",
    "from itertools import combinations\n",
    "from pyproj import Transformer\n",
    "from shapely import LineString, MultiLineString\n",
    "from shapely.geometry import Point, box\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "import time\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f07b88aa-faaa-42c1-a6e8-ed0b1ad39184",
   "metadata": {},
   "outputs": [],
   "source": [
    "mta_colors = {\n",
    "    'A': '#1373c2', 'C': '#0b4ab8', 'E': '#0b33b8', 'SIR': '#08179C', #A is 0027a6\n",
    "    'B': '#ff8c19', 'D': '#ff7919', 'F': '#FF6319', 'M': '#e66325', \n",
    "    'G': '#6CBE45', 'J': '#996633', 'Z': '#825c35', 'L': '#A7A9AC',\n",
    "    'N': '#f7d52a', 'Q': '#f2e422', 'R': '#fcBb0a', 'W': '#f0b618', \n",
    "    '1': '#d92121', '2': '#EE352E', '3': '#ed5247', \n",
    "    '4': '#21b559', '5': '#1dad46', '6': '#00933C', '7': '#B933AD', \n",
    "    'S': '#808183', 'SF': '#808183', 'ST': '#808183', 'SR': '#808183'}\n",
    "subway_speeds = {\n",
    "    'A': 1, 'C': 1, 'E': 1, 'SIR': 1,\n",
    "    'B': 1, 'D': 1, 'F': 1, 'M': 1,\n",
    "    'G': 1, 'J': 1, 'Z': 0.01, 'L': 1,\n",
    "    'N': 1, 'Q': 1, 'R': 1, 'W': 1,\n",
    "    '1': 1, '2': 1, '3': 1,\n",
    "    '4': 1, '5': 1, '6': 1, '7': 1,\n",
    "    'S': 1, 'SF': 1, 'ST': 1, 'SR': 1,\n",
    "}\n",
    "subway_lines = ['A', 'C', 'E', 'SIR', 'B', 'D', 'F', 'M', 'G', 'J', 'Z', 'L', 'N', 'Q', 'R', 'W', '1', '2', '3', '4', '5', '6', '7', 'S']\n",
    "def route_offsets(route): # jitter by this amount by index\n",
    "    if route in subway_lines:\n",
    "        return subway_lines.index(route) * 0.2\n",
    "    return -0.2\n",
    "def jitter_line(line, route_id):\n",
    "    offset = np.array(route_offsets(route_id))\n",
    "    # Add the offset to every coordinate point in the line\n",
    "    new_coords = [tuple(np.array(p) + offset) for p in line.coords]\n",
    "    return LineString(new_coords)\n",
    "def subdivide_line(line, max_length=30):\n",
    "    if line.length <= max_length:\n",
    "        return [line]\n",
    "    segments = []\n",
    "    num_segments = math.ceil(line.length / max_length)\n",
    "    points = [line.interpolate(i / num_segments, normalized=True) for i in range(num_segments + 1)]\n",
    "    for p1, p2 in zip(points[:-1], points[1:]):\n",
    "        segments.append(LineString([p1, p2]))\n",
    "    return segments\n",
    "\n",
    "\n",
    "SUBWAY_SPEED = 1.0 # used in euclidean dist\n",
    "TARGET_CRS = \"EPSG:32618\"\n",
    "\n",
    "def jittered_weight(u, v, data):\n",
    "    jitterSize = 0.03\n",
    "    base_length = data['length']\n",
    "    jitter = random.gauss(1, jitterSize)\n",
    "    return base_length * jitter\n",
    "def jitter_sqrt(u, v, data):\n",
    "    strength = 1 # strength of 1 means 10 m path will be jittered by 1 * sqrt(10) = 3\n",
    "                # or 100 m path will get jittered by 1 * sqrt (100) = 10\n",
    "    base_length = data['length']\n",
    "    if base_length <= 0:\n",
    "        return 0.001\n",
    "    sigma = strength * math.sqrt(base_length)\n",
    "    noise = random.gauss(0, sigma)\n",
    "    return max(0.001, base_length + noise)\n",
    "def euclidean_dist_heuristic(u, v):\n",
    "    return np.linalg.norm(np.array(u) - np.array(v)) / SUBWAY_SPEED \n",
    "def euclidean_dist(u, v):\n",
    "    return np.linalg.norm(np.array(u) - np.array(v))\n",
    "\n",
    "def pathfind(source_target_pair, graph, weight_func, heuristic_func, exponent_val):\n",
    "    source_node, target_node = source_target_pair\n",
    "    source_node = tuple(source_node)\n",
    "    target_node = tuple(target_node)\n",
    "    try: \n",
    "        path = nx.astar_path(graph, source_node, target_node, \n",
    "                            weight=weight_func, heuristic=heuristic_func)\n",
    "        network_dist = sum(graph.edges[u, v]['length'] for u, v in zip(path[:-1], path[1:]))\n",
    "        distance = np.linalg.norm(np.array(source_node) - np.array(target_node))\n",
    "        directness = distance / (network_dist + 0.001)\n",
    "        influence = directness ** exponent_val\n",
    "        path_edges = list(zip(path[:-1], path[1:]))\n",
    "        # Return all the edges from this path and the influence score for this path\n",
    "        return (path_edges, influence)\n",
    "    except nx.NetworkXNoPath:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8ecb1b-868e-4029-a23d-6dac51642504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "898e0677-0bd2-471b-93c3-71820e37ae1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and building graph from OpenStreetMap...\n",
      "Downloaded graph with 1 components.\n",
      "Converting graph nodes from OSM IDs to coordinates...\n"
     ]
    }
   ],
   "source": [
    "num_iterations = 2000000\n",
    "\n",
    "print(\"Downloading and building graph from OpenStreetMap...\")\n",
    "place_name = \"New York, New York\"\n",
    "TARGET_CRS = \"EPSG:32618\"\n",
    "\n",
    "bbox = (-74.253845,40.497615,-73.656464,40.981972)\n",
    "center_lon, center_lat = -73.920135,40.710313\n",
    "#center_lat, center_lon = 40.664279, -73.865331 # test near howard beach\n",
    "transformer = Transformer.from_crs(\"EPSG:4326\", TARGET_CRS, always_xy = True)\n",
    "center_x, center_y = transformer.transform(center_lon, center_lat)\n",
    "center_point = np.array([center_x, center_y])\n",
    "\n",
    "# --- 1. Get data by uncommenting below 4 lines! ---\n",
    "# G_directed = ox.graph_from_bbox(bbox = bbox, network_type='drive')\n",
    "# G_proj = ox.project_graph(G_directed, to_crs=TARGET_CRS)\n",
    "# with open('g_proj_d.pkl', 'wb') as f:\n",
    "#     pickle.dump(G_proj, f)\n",
    "\n",
    "with open('g_proj_d.pkl', 'rb') as f:\n",
    "    G_proj = pickle.load(f)\n",
    "\n",
    "G_initial = nx.Graph(G_proj)\n",
    "print(f\"Downloaded graph with {nx.number_connected_components(G_initial)} components.\")\n",
    "\n",
    "# --- 2. Convert Graph Nodes to Coordinate Tuples ---\n",
    "print(\"Converting graph nodes from OSM IDs to coordinates...\")\n",
    "pos = {node: (data['x'], data['y']) for node, data in G_initial.nodes(data=True)}\n",
    "G = nx.Graph() # This will be our final graph with coordinate nodes\n",
    "for u, v, data in G_initial.edges(data=True):\n",
    "    u_coords = pos[u]\n",
    "    v_coords = pos[v]\n",
    "    G.add_edge(u_coords, v_coords, **data)\n",
    "street_nodes = list(G.nodes())\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0abe08d0-1b33-4044-9094-6654a9e88b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffwidth = bbox[0]-bbox[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2aadc89-dc88-418b-b484-c1adc7efaa7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4843569999999957"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox[1]-bbox[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99555b2c-c948-4163-9f77-54d5f34f3480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-74.27684416849999"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox[0] + diffwidth*0.077/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5ea929a-e1ee-487c-a86f-d4b02322ec56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-73.6334648315"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox[2] - diffwidth*0.077/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b97405fd-72c8-4d9e-a4ae-8ff2c6563256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5973809999999986"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1583d4f2-7d52-413f-a41f-d4ea4cf7759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# # --- 2.5. subway! ---\n",
    "print('loading subway data...')\n",
    "\n",
    "#lines_path = \"data/nystreets/routes_nyc_subway_may2016.shp\" # 'route_id'\n",
    "lines_path = 'data/nystreets/geo_export_6c9929cb-3ce9-4cb5-862d-dc06efa13f97.shp' # 'service'\n",
    "lines_gdf = gpd.read_file(lines_path)\n",
    "lines_gdf = lines_gdf.to_crs(TARGET_CRS).explode()\n",
    "#here\n",
    "lines_gdf['route_id'] = lines_gdf['service'].map(lambda x: 'S' if len(x) == 2 else x) # call all shuttle  'S'\n",
    "lines_gdf['route_id'] = lines_gdf['route_id'].map(lambda x: '5' if x=='5 Peak' else x) \n",
    "\n",
    "all_subdivided_lines_data = []\n",
    "\n",
    "# Iterate through your original subway lines DataFrame\n",
    "for index, row in lines_gdf.iterrows():\n",
    "    original_line = row.geometry\n",
    "    original_data = row.to_dict()\n",
    "    new_segments = subdivide_line(original_line)\n",
    "    # For each new, small segment, create a new row of data\n",
    "    for seg in new_segments:\n",
    "        new_row_data = original_data.copy()\n",
    "        new_row_data['geometry'] = seg\n",
    "        all_subdivided_lines_data.append(new_row_data)\n",
    "\n",
    "lines_gdf_subdivided = gpd.GeoDataFrame(all_subdivided_lines_data, crs=TARGET_CRS)\n",
    "print(f\"Subdivision complete. Original {len(lines_gdf)} lines became {len(lines_gdf_subdivided)} segments.\")\n",
    "lines_gdf = lines_gdf_subdivided\n",
    "\n",
    "\n",
    "stations_df = pd.read_csv(\"data/nystreets/MTA_Subway_Stations.csv\")\n",
    "stations_gdf = gpd.GeoDataFrame(\n",
    "    stations_df,\n",
    "    geometry=gpd.points_from_xy(stations_df['GTFS Longitude'], stations_df['GTFS Latitude']),\n",
    "    crs=\"EPSG:4326\").to_crs(TARGET_CRS)\n",
    "stations_gdf['routes'] = stations_gdf['Daytime Routes'].str.split(' ')\n",
    "stations_gdf.columns = stations_gdf.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "# prepare street graph G\n",
    "for u, v, data in G.edges(data=True):\n",
    "    G.edges[u, v]['type'] = 'street'\n",
    "\n",
    "subG = nx.Graph()\n",
    "\n",
    "# jitter lines\n",
    "lines_gdf['geometry'] = lines_gdf.apply(\n",
    "    lambda row: jitter_line(row.geometry, row['route_id']),\n",
    "    axis=1)\n",
    "\n",
    "all_subway_data = [] # We'll create a list of dictionaries\n",
    "for index, row in lines_gdf.iterrows():\n",
    "    line = row.geometry\n",
    "    route_id = row['route_id'] \n",
    "    segments = [LineString(pair) for pair in zip(line.coords, line.coords[1:])]\n",
    "    for seg in segments:\n",
    "        all_subway_data.append({'geometry': seg, 'route_id': route_id})\n",
    "\n",
    "# --- Part 2: Build the graph from our new, detailed list ---\n",
    "for seg_data in all_subway_data:\n",
    "    segment = seg_data['geometry']\n",
    "    route_id = seg_data['route_id'] \n",
    "    start_node = (segment.coords[0])\n",
    "    end_node = (segment.coords[-1])\n",
    "    if start_node != end_node:\n",
    "        travel_time = segment.length / (SUBWAY_SPEED * subway_speeds[route_id])\n",
    "        subG.add_edge(start_node, end_node,\n",
    "                    length=travel_time, \n",
    "                    type='subway',\n",
    "                    route_id=route_id) \n",
    "endpoints_by_route = defaultdict(list)\n",
    "for index, row in lines_gdf.iterrows():\n",
    "    line = row.geometry\n",
    "    route = row['route_id']\n",
    "    if len(line.coords) > 1:\n",
    "        endpoints_by_route[route].append(line.coords[0])\n",
    "        endpoints_by_route[route].append(line.coords[-1])\n",
    "gaps_bridged = 0\n",
    "for route, endpoints in endpoints_by_route.items():\n",
    "    if len(endpoints) < 2: continue\n",
    "    unique_endpoints = list(set(endpoints))\n",
    "    endpoint_tree = KDTree(unique_endpoints)\n",
    "    gap_pairs = endpoint_tree.query_pairs(r=20) # radius for closing gaps\n",
    "    for (i, j) in gap_pairs:\n",
    "        node1 = unique_endpoints[i]\n",
    "        node2 = unique_endpoints[j]\n",
    "        dist = euclidean_dist(node1, node2)\n",
    "        if dist > 20:\n",
    "            print('oh no')\n",
    "        subG.add_edge(node1, node2, length=dist/SUBWAY_SPEED, type='subway', route_id = route)\n",
    "        gaps_bridged += 1\n",
    "print(f\"Bridged {gaps_bridged} gaps in the subway network.\")\n",
    "\n",
    "G = nx.compose(G, subG)\n",
    "\n",
    "\n",
    "# connecting stations!\n",
    "ENTER_STATION = 20 # meters from station to street (walking is ~ 1 m/s)\n",
    "TRAIN_WAIT = 180 # meters from station to getting on train (applied both ways)\n",
    "\n",
    "print(\"Connecting networks at station entrances...\")\n",
    "station_id_to_node = {}\n",
    "for station in stations_gdf.itertuples():\n",
    "    platform_coords = (station.geometry.x, station.geometry.y)\n",
    "    G.add_node(platform_coords)\n",
    "    station_id_to_node[station.station_id] = platform_coords\n",
    "\n",
    "# subway_nodes = [n for n, d in G.nodes(data=True) if G.degree(n) > 0 and all(G.edges[n, neighbor].get('type') == 'subway' for neighbor in G.neighbors(n))]\n",
    "# subway_tree = KDTree(subway_nodes)\n",
    "\n",
    "street_tree = KDTree(street_nodes) # connect station to street\n",
    "for station_id, platform_node in station_id_to_node.items():\n",
    "    dist, idx = street_tree.query(platform_node)\n",
    "    nearest_street_node = street_nodes[idx]\n",
    "    entrance_time = dist + ENTER_STATION\n",
    "    G.add_edge(platform_node, nearest_street_node, length = dist + ENTER_STATION, type='station_entrance')\n",
    "\n",
    "g_nodes = list(G.nodes())\n",
    "node_tree = KDTree(g_nodes)\n",
    "\n",
    "\n",
    "nodes_by_route = defaultdict(list)\n",
    "for u, v, data in G.edges(data=True):\n",
    "    if data.get('type') == 'subway':\n",
    "        route_id = data.get('route_id')\n",
    "        if route_id:\n",
    "            nodes_by_route[route_id].append(u)\n",
    "            nodes_by_route[route_id].append(v)\n",
    "for route, nodes in nodes_by_route.items():\n",
    "    nodes_by_route[route] = list(set(nodes))\n",
    "\n",
    "# 3. Loop through each station and find the best edge to split\n",
    "for station in stations_gdf.itertuples():\n",
    "    for route in station.routes:\n",
    "        platform_coords = (station.geometry.x, station.geometry.y)\n",
    "        platform_point = np.array(platform_coords)\n",
    "        G.add_node(platform_coords)\n",
    "\n",
    "        route_nodes = nodes_by_route.get(route)\n",
    "        route_tree = KDTree(route_nodes)\n",
    "\n",
    "        dist, idx = route_tree.query(platform_coords)\n",
    "        closest_node = route_nodes[idx]\n",
    "        \n",
    "        best_edge = None\n",
    "        min_dist_to_edge = float('inf')\n",
    "        for neighbor in G.neighbors(closest_node):\n",
    "            edge_geom = LineString([closest_node, neighbor])\n",
    "            dist = edge_geom.distance(Point(platform_coords))\n",
    "            if dist < min_dist_to_edge and G.edges[closest_node, neighbor]['type'] == 'subway':\n",
    "                min_dist_to_edge = dist\n",
    "                best_edge = (closest_node, neighbor)\n",
    "                \n",
    "        if best_edge:\n",
    "            # We found the correct edge in G to split\n",
    "            u, v = best_edge\n",
    "            edge_data = G.edges[u, v].copy() # Get its attributes\n",
    "            \n",
    "            # Create the new connection point\n",
    "            new_node = tuple(LineString(best_edge).interpolate(LineString(best_edge).project(Point(platform_coords))).coords[0])\n",
    "            \n",
    "            # Perform the split-and-insert directly on G\n",
    "            G.remove_edge(u, v)\n",
    "            G.add_edge(u, new_node, **edge_data)\n",
    "            G.add_edge(new_node, v, **edge_data)\n",
    "\n",
    "            edist = euclidean_dist(new_node, platform_coords)\n",
    "            if edist > 200:\n",
    "                print(f\"platform track dist {edist:.0f}m for route {route} at {station.stop_name}\")\n",
    "                print(euclidean_dist(u, platform_coords))\n",
    "                print(euclidean_dist(v, platform_coords))\n",
    "                print(u)\n",
    "                print(v)\n",
    "                print(new_node)\n",
    "                print(platform_coords)\n",
    "            \n",
    "            # Add the final connection from the platform to the new split point\n",
    "            G.add_edge(platform_coords, new_node, \n",
    "                    length=TRAIN_WAIT, type='platform_access')\n",
    "\n",
    "# adding stop time penalties\n",
    "STOP_TIME = 30 # applied twice while passing a station\n",
    "track_nodes_with_stops = set()\n",
    "for station_id, platform_node in station_id_to_node.items():\n",
    "    for neighbor in G.neighbors(platform_node):\n",
    "        if G.edges[platform_node, neighbor].get('type') == 'platform_access':\n",
    "            track_nodes_with_stops.add(neighbor)\n",
    "for track_node in track_nodes_with_stops:\n",
    "    for neighbor in G.neighbors(track_node):\n",
    "        edge_data = G.edges[track_node, neighbor]\n",
    "        if edge_data.get('type') == 'subway':\n",
    "            #G.edges[u, v]['length'] = G.edges[u, v]['length']\n",
    "            G.edges[track_node, neighbor]['length'] = G.edges[track_node,neighbor]['length'] + STOP_TIME\n",
    "    \n",
    "print(\"Multi-modal graph creation complete!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7be877c-c44f-48b1-a326-1bda3fbd2f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading population...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anita\\anaconda3\\Lib\\site-packages\\pyogrio\\core.py:35: RuntimeWarning: Could not detect GDAL data files.  Set GDAL_DATA environment variable to the correct path.\n",
      "  _init_gdal_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully. Found 3014 population grid cells.\n",
      "Selecting paths...\n",
      "Sampling complete. 19726 pairs were accepted for pathfinding.\n",
      "Running pathfinding on accepted pairs...\n",
      "running parallel...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 2.6 load population! --\n",
    "print('loading population...')\n",
    "kontur_filepath = \"../data/nystreets/kontur_population_US_20231101.gpkg\"\n",
    "pop_gdf_info = gpd.read_file(kontur_filepath, rows=1)\n",
    "\n",
    "west, south, east, north = -74.253845, 40.497615, -73.656464, 40.981972\n",
    "bbox_gdf_latlon = gpd.GeoDataFrame(\n",
    "    geometry=[box(west, south, east, north)],\n",
    "    crs=\"EPSG:4326\")\n",
    "bbox_gdf_projected = bbox_gdf_latlon.to_crs(\"EPSG:3857\")\n",
    "projected_bbox_coords = tuple(bbox_gdf_projected.total_bounds)\n",
    "pop_gdf = gpd.read_file(\n",
    "    kontur_filepath,\n",
    "    bbox=projected_bbox_coords).to_crs(TARGET_CRS)\n",
    "    \n",
    "pop_centers_gdf = pop_gdf.copy() # collapse to centers\n",
    "pop_centers_gdf['geometry'] = pop_centers_gdf.geometry.centroid\n",
    "pop_points = np.array([p.coords[0] for p in pop_centers_gdf.geometry])\n",
    "pop_values = pop_centers_gdf['population'].values\n",
    "pop_tree = KDTree(pop_points)\n",
    "print(f\"Data loaded successfully. Found {len(pop_gdf)} population grid cells.\")\n",
    "\n",
    "# --- 3. Run Pathfinding Simulation ---\n",
    "print(\"Selecting paths...\")\n",
    "all_nodes = list(G.nodes)\n",
    "all_edges = list(G.edges)\n",
    "final_weights = []\n",
    "for u, v, data in G.edges(data=True):\n",
    "    G.edges[u, v]['usage'] = 0\n",
    "\n",
    "shortDistance = 1000\n",
    "exponent = 2.3  \n",
    "proximity_sigma = 27000 # 1.6 km per mile\n",
    "\n",
    "# calculate probability of being picked of edges\n",
    "u_coords = np.array([u for u, v in all_edges])\n",
    "v_coords = np.array([v for u, v in all_edges])\n",
    "midpoints = (u_coords + v_coords)/2\n",
    "lengths = np.array(list(nx.get_edge_attributes(G, 'length').values()))\n",
    "# dist_center = np.linalg.norm(u_coords - center_point, axis=1)\n",
    "prox_weight = 1 #np.exp(-(dist_center**2) / (2 * proximity_sigma**2))\n",
    "\n",
    "pop_distances, pop_indices = pop_tree.query(midpoints, k=1)\n",
    "edge_pops = pop_values[pop_indices]\n",
    "# normalize by total edge length in hexagon\n",
    "temp_df = pd.DataFrame({'edge_length': lengths, 'population': edge_pops, 'hexagon_id': pop_indices})\n",
    "hexagon_total_lengths = temp_df.groupby('hexagon_id')['edge_length'].sum()\n",
    "temp_df['hexagon_total_length'] = temp_df['hexagon_id'].map(hexagon_total_lengths)\n",
    "normalized_length_weight = temp_df['edge_length'] / temp_df['hexagon_total_length']\n",
    "# square root because weight will be applied once at source and once at destination\n",
    "pop_weight = ((temp_df['population'] / (temp_df['population'].max() + 1)) + 0.01)**0.5\n",
    "\n",
    "final_weights = lengths * prox_weight * pop_weight\n",
    "\n",
    "# do random selections\n",
    "probabilities = final_weights / np.sum(final_weights)\n",
    "edge_indices = np.arange(len(all_edges))\n",
    "all_edges_array = np.array(all_edges)\n",
    "chosen_indices = np.random.choice(edge_indices, size=(num_iterations, 2), p=probabilities)\n",
    "source_edges = all_edges_array[chosen_indices[:, 0]]\n",
    "target_edges = all_edges_array[chosen_indices[:, 1]]\n",
    "source_endpoint_choices = np.random.randint(2, size=num_iterations)\n",
    "target_endpoint_choices = np.random.randint(2, size=num_iterations)\n",
    "source_nodes = source_edges[np.arange(num_iterations), source_endpoint_choices]\n",
    "target_nodes = target_edges[np.arange(num_iterations), target_endpoint_choices]\n",
    "# calculate distances\n",
    "dists = np.linalg.norm(source_nodes - target_nodes, axis=1)\n",
    "# filter out bad paths\n",
    "acceptance_mask = dists <= shortDistance\n",
    "long_dists = dists[~acceptance_mask]\n",
    "probs_long = (shortDistance / long_dists) ** exponent\n",
    "rolls_long = np.random.random(size=len(long_dists))\n",
    "acceptance_mask[~acceptance_mask] = rolls_long < probs_long\n",
    "final_source_nodes = source_nodes[acceptance_mask]\n",
    "final_target_nodes = target_nodes[acceptance_mask]\n",
    "successful_selections = len(final_source_nodes)\n",
    "print(f\"Sampling complete. {successful_selections} pairs were accepted for pathfinding.\")\n",
    "\n",
    "print(\"Running pathfinding on accepted pairs...\")\n",
    "start_time = time.time()\n",
    "successful_paths = 0\n",
    "failed_paths = 0\n",
    "\n",
    "parallel = successful_selections > 1200    \n",
    "if parallel:\n",
    "    print('running parallel...')\n",
    "    pathfinding_jobs = list(zip(final_source_nodes, final_target_nodes))\n",
    "    worker_func = partial(pathfind, graph=G, weight_func = jitter_sqrt, \n",
    "        heuristic_func = euclidean_dist_heuristic, exponent_val=exponent)\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    with multiprocessing.Pool(processes = num_cores - 2) as pool:\n",
    "        results = pool.map(worker_func, pathfinding_jobs)\n",
    "    successful_paths = 0\n",
    "    for result in results:\n",
    "        if result is not None:\n",
    "            path_edges, influence = result\n",
    "            successful_paths += 1\n",
    "            for u, v in path_edges:\n",
    "                G.edges[u, v]['usage'] += influence\n",
    "else: \n",
    "    for i, (source_node, target_node) in enumerate(zip(final_source_nodes, final_target_nodes)):\n",
    "        try:\n",
    "            path = nx.astar_path(G, tuple(source_node), tuple(target_node), \n",
    "                                weight=jitter_sqrt, heuristic=euclidean_dist_heuristic)\n",
    "            network_dist = sum(G.edges[u, v]['length'] for u, v in zip(path[:-1], path[1:]))\n",
    "            distance = euclidean_dist(source_node, target_node)\n",
    "            directness = distance / (network_dist + 0.001)\n",
    "            if directness >= SUBWAY_SPEED:\n",
    "                print ('directness ' + str(directness))\n",
    "            for u, v in zip(path[:-1], path[1:]):\n",
    "                G.edges[u, v]['usage'] += directness**exponent\n",
    "            successful_paths += 1\n",
    "            if successful_paths > 0 and successful_paths % 1000 == 0:\n",
    "                print(f\"  ...found {successful_paths}/{successful_selections} paths...\")\n",
    "\n",
    "        except nx.NetworkXNoPath:\n",
    "            failed_paths += 1\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Pathfinding complete. {successful_paths}/{successful_selections} successful paths found. took {end_time-start_time:.2f} seconds, {(end_time-start_time)/successful_paths:5f} each.\")\n",
    "\n",
    "# --- Step 4: Create Final GeoDataFrame ---\n",
    "# --- 4a: Start with the original street geometries from G_proj ---\n",
    "df_streets = ox.graph_to_gdfs(G_proj, nodes=False)\n",
    "\n",
    "# Map the calculated 'usage' from your main graph G back to this GeoDataFrame\n",
    "print(\"Mapping usage counts to street geometries...\")\n",
    "usage_counts = []\n",
    "for u_osmid, v_osmid, data in G_proj.edges(data=True, keys=False):\n",
    "    # Get the coordinate-based nodes used in your main graph G\n",
    "    u_coords = (G_initial.nodes[u_osmid]['x'], G_initial.nodes[u_osmid]['y'])\n",
    "    v_coords = (G_initial.nodes[v_osmid]['x'], G_initial.nodes[v_osmid]['y'])\n",
    "    # Look up the edge in G to find its usage\n",
    "    edge_data = G.get_edge_data(u_coords, v_coords)\n",
    "    if edge_data:\n",
    "        usage_counts.append(edge_data.get('usage', 0))\n",
    "    else: # This might happen if the edge was removed from G, though unlikely here\n",
    "        usage_counts.append(0)\n",
    "df_streets['usage'] = usage_counts\n",
    "df_streets['type'] = 'street'\n",
    "df_streets['route_id'] = None\n",
    "\n",
    "# --- 4b: Create geometries for all NON-street edges (subway, transfers, etc.) ---\n",
    "print(\"Creating geometries for subway and other network edges...\")\n",
    "other_edges_data = []\n",
    "for u, v, data in G.edges(data=True):\n",
    "    if data.get('type') != 'street':\n",
    "        geom = LineString([u, v])\n",
    "        other_edges_data.append({\n",
    "            'geometry': geom,\n",
    "            'usage': data.get('usage', 0),\n",
    "            'type': data.get('type', 'unknown'),\n",
    "            'route_id': data.get('route_id', None)\n",
    "        })\n",
    "df_other = gpd.GeoDataFrame(other_edges_data, crs=TARGET_CRS)\n",
    "# --- 4c: Combine the two GeoDataFrames ---\n",
    "print(\"Combining street and subway GeoDataFrames...\")\n",
    "df = pd.concat([df_streets, df_other], ignore_index=True)\n",
    "\n",
    "# Select only the columns you need for plotting to keep things clean\n",
    "df = df[['geometry', 'usage', 'type', 'route_id']]\n",
    "print(\"Final combined GeoDataFrame created successfully.\")\n",
    "\n",
    "# save!\n",
    "df.to_file('usage_map.gpkg', driver='GPKG')\n",
    "print('File saved.')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480eb8cb-2d05-4d5b-82ec-5e6bed34571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('loading file...')\n",
    "df = gpd.read_file('usage_map.gpkg')\n",
    "\n",
    "print(\"Plotting final map...\")\n",
    "imageSize = 100\n",
    "fig, ax = plt.subplots(figsize=(imageSize, imageSize))\n",
    "ax.set_facecolor('black')\n",
    "ax.set_axis_off()\n",
    "xmin, ymin, xmax, ymax = df.total_bounds\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.set_ylim(ymin, ymax)\n",
    "\n",
    "cmap = 'magma'\n",
    "\n",
    "width_exp = 0.72\n",
    "maxWidth = 0.15\n",
    "maxUsage = df.usage.max()\n",
    "\n",
    "streets_df = df[(df['type'] != 'subway')].sort_values('usage', ascending=True)\n",
    "subway_df = df[df['type'] == 'subway'].copy()\n",
    "subway_df['routeColor'] = subway_df['route_id'].map(mta_colors).fillna('#FFFFFF')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(imageSize, imageSize))\n",
    "ax.set_facecolor('black')\n",
    "ax.set_axis_off()\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.set_ylim(ymin, ymax)\n",
    "streets_df.plot(ax=ax, column='usage', cmap=cmap, \n",
    "    linewidth = maxWidth * imageSize * streets_df['usage']**width_exp / maxUsage**width_exp, \n",
    "    norm=LogNorm(vmin=0.2, vmax=df['usage'].max()*0.8), capstyle='round'    \n",
    ")\n",
    "plt.savefig('nystreets/osmsub' + '.png', pad_inches=0, facecolor='black')\n",
    "print('plot saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f227e5-19bd-43c9-badb-2d2586fb693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "streets_df.plot(\n",
    "    ax=ax,\n",
    "    column='usage',\n",
    "    cmap=cmap, \n",
    "    linewidth = maxWidth * imageSize * streets_df['usage']**width_exp / maxUsage**width_exp, \n",
    "    norm=LogNorm(vmin=0.2, vmax=df['usage'].max()*0.8),\n",
    "    capstyle='round'    \n",
    ")\n",
    "\n",
    "subway_df = subway_df.sort_values('usage', ascending=True)\n",
    "subway_df.plot( ax=ax, color = subway_df['routeColor'],\n",
    "    linewidth = maxWidth * imageSize * subway_df['usage']**width_exp / maxUsage**width_exp, \n",
    "    alpha=0.99, capstyle='round', \n",
    ")\n",
    "# subway_df.plot( ax=ax, column='usage', cmap=cmap, \n",
    "#     linewidth = maxWidth * imageSize * subway_df['usage']**width_exp / maxUsage**width_exp, \n",
    "#     norm=LogNorm(vmin=0.3, vmax=df['usage'].max()*0.8), capstyle='round'    \n",
    "# )\n",
    "plt.savefig('nystreets/osmsuball' + '.png', pad_inches=0, facecolor='black')\n",
    "print('plot saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65033a4b-2142-48ae-8929-9356755b212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for route in subway_lines:\n",
    "    line_df = df[df.route_id == route]\n",
    "    if not line_df.empty:\n",
    "        fig_layer, ax_layer = plt.subplots(figsize=(imageSize, imageSize))\n",
    "        ax_layer.set_facecolor('none')\n",
    "        ax_layer.set_axis_off()\n",
    "        ax_layer.set_xlim(xmin, xmax)\n",
    "        ax_layer.set_ylim(ymin, ymax)\n",
    "\n",
    "        line_df.plot(ax=ax_layer,\n",
    "            color = mta_colors[route],\n",
    "            linewidth = np.maximum(0.1, maxWidth * imageSize * line_df['usage']**width_exp / maxUsage**width_exp), # max is new\n",
    "            capstyle='round')\n",
    "        fig_layer.savefig('nystreets/lines/' + route + '.png', pad_inches=0, facecolor='none')\n",
    "        plt.close(fig_layer)\n",
    "\n",
    "print('line plots saved!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68194268-39d6-46a8-8ae4-a4767aca4907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a298c22-3926-49db-8219-833d7eb0bb98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ca17cd-f401-47e8-bce8-a42d43a7f3f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bb0222-ae5d-4af9-ad84-4d17688b4217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f527eb8a-b988-47fe-a409-dac9a122f8be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d07cf02-0157-4a1a-b8ca-1364f088531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #PLOTTING ----------------------------------\n",
    "#     #bbox_latlon = (-73.988, 40.745, -73.970, 40.758) \n",
    "#     bbox_latlon = (-73.961066,40.772774,-73.958652,40.774562) #77th st \n",
    "#     bbox_latlon = (-73.964950,40.767131,-73.963303,40.768549) #68th st\n",
    "#     transformer = Transformer.from_crs(\"EPSG:4326\", TARGET_CRS, always_xy=True)\n",
    "#     min_lon, min_lat, max_lon, max_lat = bbox_latlon\n",
    "#     bottom_left = transformer.transform(min_lon, min_lat)\n",
    "#     top_right = transformer.transform(max_lon, max_lat)\n",
    "\n",
    "#     # bottom_left = (586130, 4511430)\n",
    "#     # top_right = (586165, 4511455)\n",
    "#     area_of_interest = box(bottom_left[0], bottom_left[1], top_right[0], top_right[1])\n",
    "\n",
    "#     print(\"Creating a subgraph for the target area...\")\n",
    "#     nodes_in_box = [n for n in G.nodes() if Point(n).within(area_of_interest)]\n",
    "#     G_zoomed = G.subgraph(nodes_in_box)\n",
    "#     print(f\"Subgraph created with {G_zoomed.number_of_nodes()} nodes and {G_zoomed.number_of_edges()} edges.\")\n",
    "\n",
    "#     # Prepare Edges\n",
    "#     edge_data = []\n",
    "#     for u, v, data in G_zoomed.edges(data=True):\n",
    "#         network_length = data.get('length', 0)\n",
    "#         edist = np.linalg.norm(np.array(u) - np.array(v))\n",
    "#         circuity = network_length / (edist + 1e-6)\n",
    "#         edge_data.append({\n",
    "#             'geometry': LineString([u,v]),\n",
    "#             'type': data.get('type'),\n",
    "#             'circuity': circuity\n",
    "#         })\n",
    "#     edges_gdf = gpd.GeoDataFrame(edge_data, crs=TARGET_CRS)\n",
    "#     node_data = []\n",
    "#     for node in G_zoomed.nodes():\n",
    "#         node_data.append({\n",
    "#             'geometry': Point(node),\n",
    "#             'degree': G_zoomed.degree(node)\n",
    "#         })\n",
    "#     nodes_gdf = gpd.GeoDataFrame(node_data, crs=TARGET_CRS)\n",
    "\n",
    "#     print(\"Plotting diagnostic map...\")\n",
    "#     fig, ax = plt.subplots(figsize=(50, 50))\n",
    "#     ax.set_facecolor('white')\n",
    "#     ax.set_axis_off()\n",
    "\n",
    "#     edges_gdf.plot(ax=ax, column='circuity', cmap='coolwarm', linewidth=0.5, legend=True,\n",
    "#                 legend_kwds={'label': \"Edge Circuity (Network Length / Straight-Line Length)\"}, alpha=0.5)\n",
    "#     nodes_gdf.plot(ax=ax, column='degree', cmap='spring', markersize=8, legend=True,\n",
    "#                 legend_kwds={'label': \"Node Degree (Number of Connections)\"}, alpha=0.4)\n",
    "\n",
    "#     plt.savefig('debug_grand_central.png', bbox_inches='tight', pad_inches=0, facecolor='white', dpi=300)\n",
    "#     print(\"Diagnostic plot saved to 'debug_grand_central.png'\")\n",
    "\n",
    "\n",
    "    # # PLOTTING\n",
    "    # #     # START OTHER PLOTTING\n",
    "    # # --- 2. Define a Wider Area of Interest for the 4 Train ---\n",
    "    # bbox_latlon_4train = (-73.956356,40.630630,-73.886662,40.673673) \n",
    "\n",
    "    # # Project the bounding box to your script's CRS\n",
    "    # transformer = Transformer.from_crs(\"EPSG:4326\", TARGET_CRS, always_xy=True)\n",
    "    # min_lon, min_lat, max_lon, max_lat = bbox_latlon_4train\n",
    "    # bottom_left = transformer.transform(min_lon, min_lat)\n",
    "    # top_right = transformer.transform(max_lon, max_lat)\n",
    "    # area_of_interest_4train = box(bottom_left[0], bottom_left[1], top_right[0], top_right[1])\n",
    "\n",
    "    # # --- 3. Filter for 4 Train Edges and Nodes within the Area ---\n",
    "    # print(\"Filtering for 4 train network in the specified area...\")\n",
    "    # line_edges_in_area = []\n",
    "    # line_nodes_in_area = set()\n",
    "\n",
    "    # excluded = ['4', '5']\n",
    "    # for u, v, data in G.edges(data=True):\n",
    "    #     # Ensure it's a subway edge and is for the '4' train, and within the bbox\n",
    "    #     if ((data.get('type') == 'subway' or data.get('type') == 'platform_access') and \n",
    "    #         not (data.get('route_id') in excluded)):\n",
    "    #         line_geom = LineString([u, v])\n",
    "    #         if line_geom.intersects(area_of_interest_4train):\n",
    "    #             line_edges_in_area.append({'geometry': line_geom, 'usage': data.get('usage', 0), 'type': data.get('type')})\n",
    "    #             line_nodes_in_area.add(u)\n",
    "    #             line_nodes_in_area.add(v)\n",
    "\n",
    "    # debug_lines_gdf = gpd.GeoDataFrame(line_edges_in_area, crs=TARGET_CRS)\n",
    "\n",
    "    # # --- 4. Identify Non-Degree-2 Nodes on the 4 Train ---\n",
    "    # special_nodes_data = []\n",
    "    # for node_coords in line_nodes_in_area:\n",
    "    #     degree = G.degree(node_coords)\n",
    "    #     if degree != 0:\n",
    "    #         special_nodes_data.append({\n",
    "    #             'geometry': Point(node_coords),\n",
    "    #             'degree': degree,\n",
    "    #         })\n",
    "\n",
    "    # special_nodes_gdf = gpd.GeoDataFrame(special_nodes_data, crs=TARGET_CRS)\n",
    "\n",
    "    # # --- 5. Plot the Diagnostic Map ---\n",
    "    # print(\"Plotting diagnostic map of 4 train special nodes...\")\n",
    "    # fig, ax = plt.subplots(figsize=(25, 25))\n",
    "    # ax.set_facecolor('black')\n",
    "    # ax.set_axis_off()\n",
    "\n",
    "    # # Plot the 4 train line itself as a dim background\n",
    "    # debug_lines_gdf.plot(ax=ax, color='grey', linewidth=0.8, alpha=0.6)\n",
    "    # debug_lines_gdf[debug_lines_gdf['type'] == 'platform_access'].plot(ax=ax, color='red', linewidth=0.8, alpha=0.6)\n",
    "    # print(len(debug_lines_gdf[debug_lines_gdf['type'] == 'platform_access']))\n",
    "\n",
    "    # # Plot the special nodes, colored by their degree\n",
    "    # if not special_nodes_gdf.empty:\n",
    "    #     special_nodes_gdf.plot(ax=ax, markersize=10, alpha=0.4, \n",
    "    #         column = 'degree', cmap='viridis')\n",
    "\n",
    "    # plt.savefig('debug_4train_special_nodes.png', bbox_inches='tight', pad_inches=0, facecolor='white', dpi=300)\n",
    "    # print(\"Diagnostic plot saved to 'debug_4train_special_nodes.png'\")\n",
    "    # exit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
